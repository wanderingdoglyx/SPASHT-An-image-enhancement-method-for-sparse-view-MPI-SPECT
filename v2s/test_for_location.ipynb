{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_3Dden_AR_v28_custom_loop\n",
    "from train_3Dden_AR_v28_custom_loop import train_seg3D\n",
    "import os\n",
    "\n",
    "version=28\n",
    "\n",
    "job_ind=1\n",
    "lambda_val_ind_mdiff=2\n",
    "\n",
    "\n",
    "num_lambda=10\n",
    "lambda_val_ind_chdiff= (job_ind - 1) % num_lambda \n",
    "dose_level_ind= (job_ind - 1) / num_lambda \n",
    "dose_level_arr=[ 6, 5, 4, 3, 2, 7, 8]\n",
    "dose_level=dose_level_arr[int(dose_level_ind)]\n",
    "\n",
    "\n",
    "epochs=2\n",
    "batch_size_arr=32\n",
    "num_iter=8\n",
    "\n",
    "\n",
    "base_folder='/data01/user-storage/y.zezhang/data_for_zezhang_mar29'\n",
    "learning_folder='den_3d_v'+str(version)\n",
    "full_learning_folder=base_folder+'/learning/'\n",
    "\n",
    "full_learning_folder=os.path.join(full_learning_folder, learning_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights_name= 'wt_v'+str(version)\n",
    "loss_fn_name ='ls_v'+str(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" @Author: Ashequr Rahman\n",
    "    @Date: 2022-05-22  \n",
    "    @Last Modified by: Ashequr Rahman \n",
    "    @Last Modified time: 2022-05-22 \n",
    "    @Modifications: 1)Implemented 3D denoising model (concat and addition models) \n",
    "\"\"\"\n",
    "#=============================================================================================================================\n",
    "## Import Libraries  ##\n",
    "#=============================================================================================================================\n",
    "import sys, os, gc\n",
    "from pathlib import Path\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, MaxPooling3D, Dropout, BatchNormalization, concatenate, Add, Activation, LeakyReLU\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import os\n",
    "#import network model\n",
    "from Den3D_Model_AR_v1_Loop import build_dennet3D, ClearMemory\n",
    "plt.switch_backend('Agg')\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_val_chdiff: 0\n",
      "lambda_val_mdiff: 0.5\n"
     ]
    }
   ],
   "source": [
    "  lambda_val_arr_chdiff = [0, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 3e-1, 1e0, 5e0, 1e1]\n",
    "  lambda_val_arr_mdiff = [0, 1e-1, 5e-1, 1e0, 5e0, 1e1, 3e1, 1e2, 5e2, 1e3]\n",
    "  lambda_val_chdiff = lambda_val_arr_chdiff[lambda_val_ind_chdiff]\n",
    "  lambda_val_mdiff = lambda_val_arr_mdiff[lambda_val_ind_mdiff]\n",
    "  print(f'lambda_val_chdiff: {lambda_val_chdiff}')\n",
    "  print(f'lambda_val_mdiff: {lambda_val_mdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  data_folder = f'{base_folder}/training_data_sa_wd_fix2_48cube'\n",
    "  data_folder_prev = f'{base_folder}/training_data_sa_wd'\n",
    "  mod_data_folder = f'{base_folder}/learning/{learning_folder}'\n",
    "\n",
    "  # load protocols\n",
    "  dose_level_max = 1\n",
    "  num_z_slice = 64\n",
    "  num_reg = 1\n",
    "  Nx_in, Ny_in, Nz_in = 48, 48, 48\n",
    "  Nz_in_prev = 32\n",
    "  num_input_channels = 1\n",
    "  num_output_channels = num_reg\n",
    "  Nx_out, Ny_out, Nz_out = 48, 48, 48\n",
    "  Nz_out_prev = 32\n",
    "\n",
    "  input_shape = (Nx_in, Ny_in, Nz_in, num_input_channels)\n",
    "  input_shape_prev = (Nx_in, Ny_in, Nz_in_prev, num_input_channels)\n",
    "  loc_shape = (Nx_in, Ny_in, 1)\n",
    "  input_shape_orig = (Nz_in, Ny_in, Nx_in, num_input_channels)\n",
    "  input_shape_orig_prev = (Nz_in_prev, Ny_in, Nx_in, num_input_channels)\n",
    "  output_shape = (Nx_out, Ny_out, Nz_out, num_output_channels)\n",
    "  output_shape_orig = (Nz_out, Ny_out, Nx_out, num_output_channels)\n",
    "  output_shape_orig_prev = (Nz_out_prev, Ny_out, Nx_out, num_output_channels)\n",
    "\n",
    "  num_pat = 184\n",
    "  num_data_dict = {\n",
    "        'hl': {\n",
    "                'start_ind': 0,\n",
    "                'end_ind': num_pat-1,\n",
    "              },\n",
    "        'def': {\n",
    "                'start_ind': 0,\n",
    "                'end_ind': num_pat-1,\n",
    "              }\n",
    "      }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data allocated\n",
      "Y_data allocated\n"
     ]
    }
   ],
   "source": [
    "  loc_arr = ['a', 'i']                  #############################################################\n",
    "  sev_arr = [100, 175, 250]             #############################################################\n",
    "  ext_arr = [30, 60]                    #############################################################\n",
    "\n",
    "  remove_indices = [] # 3, 51, def center not in center  # remove indice 1 in test case#[77,90,110,140]\n",
    "  num_train_hl = num_data_dict['hl']['end_ind'] - num_data_dict['hl']['start_ind'] + 1\n",
    "  num_train_def = num_data_dict['def']['end_ind'] - num_data_dict['def']['start_ind'] + 1\n",
    "  num_train = num_train_hl*len(loc_arr)*len(ext_arr) + num_train_def * len(loc_arr)* len(ext_arr) * len(sev_arr)\n",
    "  X_data = np.zeros((num_train,) + input_shape)\n",
    "  print(\"X_data allocated\")\n",
    "  Y_data = np.zeros((num_train,) + output_shape)\n",
    "  Y_data_loc = np.zeros((num_train,) + loc_shape)\n",
    "  Y_data_mask = np.zeros((num_train,) + input_shape)\n",
    "  print(\"Y_data allocated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  pat_id_arr_fname = os.listdir(\"/data01/user-storage/y.zezhang/segementation/data_for_zezhang_mar29/training_data_sa_wd_fix2_48cube\")\n",
    "  #pat_id_arr_fname = f'{base_folder}/train_pat_list_def_mc.txt'\n",
    "  pat_id_arr = np.loadtxt(pat_id_arr_fname, dtype = 'str', comments=\"#\", delimiter=\",\", unpack=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_bin(cur_inp_file, data_type, input_shape):\n",
    "  A = np.fromfile(cur_inp_file, dtype = data_type)\n",
    "  A[np.isnan(A)] = 0\n",
    "  A = np.reshape(A, input_shape)\n",
    "  A = np.transpose(A, [2, 1, 0, 3])\n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data = 1e2\n",
    "j = 0\n",
    "hd='hl'\n",
    "ind_pat=0\n",
    "cur_inp_file = f'{data_folder}/{pat_id_arr[ind_pat]}/{hd}/recon_pat{pat_id_arr[ind_pat]}_d{dose_level}_it{num_iter}_c30o5.img'\n",
    "cur_label_file = f'{data_folder}/{pat_id_arr[ind_pat]}/{hd}/recon_pat{pat_id_arr[ind_pat]}_d{dose_level_max}_it{num_iter}_c30o5.img'\n",
    "cur_X = my_read_bin(cur_inp_file, 'float32', input_shape_orig)\n",
    "cur_Y = my_read_bin(cur_label_file, 'float32', input_shape_orig)\n",
    "cur_X = (cur_X - np.min(cur_X))/(np.max(cur_X) - np.min(cur_X))*sc_data\n",
    "cur_Y = (cur_Y - np.min(cur_Y))/(np.max(cur_Y) - np.min(cur_Y))*sc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=loc_arr[0]\n",
    "ext=ext_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "          def_loc_fname = f'{data_folder_prev}/{pat_id_arr[ind_pat]}/def_mask_d{loc}21{ext}.bin'\n",
    "          cur_mask = my_read_bin(def_loc_fname, 'uint8', input_shape_orig_prev)\n",
    "          def_loc_fname = f'{data_folder_prev}/{pat_id_arr[ind_pat]}/def_centroid_d{loc}21{ext}_mod.bin'\n",
    "          cur_loc = np.fromfile(def_loc_fname, dtype = 'float32').astype(int) - 1 + 1 #0 -based / but nn2D has 1 shift\n",
    "\n",
    "          X_data[j,:, :, :, :] = cur_X\n",
    "          Y_data[j,:, :, :, :] = cur_Y\n",
    "          Y_data_mask[j,:, :, -Nz_in_prev//2+Nz_in//2:Nz_in//2+Nz_in_prev//2, :] = cur_mask #8:39\n",
    "          Y_data_loc[j, cur_loc[1] , cur_loc[0], 0] = 1.0\n",
    "          j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "  X_data = X_data[:j, :, :, :, :]\n",
    "  Y_data = Y_data[:j, :, :, :, :]\n",
    "  Y_data_loc = Y_data_loc[:j, :]\n",
    "  Y_data_mask = Y_data_mask[:j, :, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data01/user-storage/y.zezhang/data_for_zezhang_mar29/training_data_sa_wd/80846029/def_centroid_da2130_mod.bin'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_loc_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 18, 17])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fromfile(def_loc_fname, dtype = 'float32').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data_loc[j, cur_loc[1] , cur_loc[0], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data_loc = Y_data_loc[:j, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(Y_data_loc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
